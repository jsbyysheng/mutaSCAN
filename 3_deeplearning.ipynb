{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys, os, distutils.core\n",
    "\n",
    "import torch, detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultTrainer, DefaultPredictor, default_argument_parser, default_setup, launch\n",
    "from detectron2.engine.hooks import HookBase\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer, ColorMode\n",
    "from detectron2.utils.logger import log_every_n_seconds\n",
    "from detectron2.data import detection_utils as utils\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog, build_detection_test_loader, build_detection_train_loader\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.structures import BoxMode\n",
    "from detectron2.evaluation import COCOEvaluator\n",
    "\n",
    "import detectron2.data.transforms as T\n",
    "import detectron2.utils.comm as comm\n",
    "\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import copy\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "import time\n",
    "import datetime\n",
    "import logging\n",
    "\n",
    "import utility\n",
    "CACHE_DIR = Path('./caches')\n",
    "utility.create_directory(CACHE_DIR)\n",
    "OUTPUT_DIR = Path('./output')\n",
    "utility.create_directory(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"torch: \", torch.__version__)\n",
    "print(\"detectron2:\", detectron2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv2_imshow(im, title='figure', figsize=(20, 20), bgr2rgb=False):\n",
    "    if isinstance(im, torch.Tensor):\n",
    "        im = im.permute(1, 2, 0).cpu().numpy().astype(np.uint8)\n",
    "    plt.figure(figsize=figsize)\n",
    "    if bgr2rgb:\n",
    "        im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(im)\n",
    "    plt.title(title)\n",
    "\n",
    "def get_data_dicts(coco_json_dir, img_dir):\n",
    "    with open(coco_json_dir) as f:\n",
    "        imgs_anns = json.load(f)\n",
    "\n",
    "    dataset_dicts = []\n",
    "\n",
    "    for annotation_obj in imgs_anns[\"annotations\"]:\n",
    "        annotation_obj['bbox_mode'] = BoxMode.XYWH_ABS\n",
    "\n",
    "    for image_obj in imgs_anns[\"images\"]:\n",
    "        record = {}\n",
    "        record[\"file_name\"] = str(Path(img_dir) / Path(image_obj['file_name']))\n",
    "        record[\"height\"] = image_obj['height']\n",
    "        record[\"width\"] = image_obj['width']\n",
    "        record[\"image_id\"] = image_obj['id']\n",
    "        record[\"annotations\"] = []\n",
    "        for annotation_obj in imgs_anns[\"annotations\"]:\n",
    "            if annotation_obj['image_id'] == image_obj['id']:\n",
    "                record[\"annotations\"].append(annotation_obj)\n",
    "        dataset_dicts.append(record)\n",
    "    return dataset_dicts\n",
    "\n",
    "class CustomMapper():\n",
    "    def __init__(self, cfg, transform_list=[]):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.transform_list = transform_list\n",
    "        self.transform_list.append(T.ResizeShortestEdge([cfg.INPUT.MIN_SIZE_TEST, cfg.INPUT.MIN_SIZE_TEST], cfg.INPUT.MAX_SIZE_TEST))\n",
    "\n",
    "    def __call__(self, dataset_dict):\n",
    "        dataset_dict = copy.deepcopy(dataset_dict)\n",
    "        image = utils.read_image(dataset_dict[\"file_name\"], format=\"BGR\")\n",
    "        image, transforms = T.apply_transform_gens(self.transform_list, image)\n",
    "        dataset_dict[\"image\"] = torch.as_tensor(image.transpose(2, 0, 1).astype(\"float32\"))\n",
    "        annos = [\n",
    "            utils.transform_instance_annotations(annotation, transforms, image.shape[:2])\n",
    "            for annotation in dataset_dict.pop(\"annotations\")\n",
    "            if annotation.get(\"iscrowd\", 0) == 0\n",
    "        ]\n",
    "        instances = utils.annotations_to_instances(annos, image.shape[:2])\n",
    "        dataset_dict[\"instances\"] = utils.filter_empty_instances(instances)\n",
    "        return dataset_dict\n",
    "\n",
    "class LossEvalHook(HookBase):\n",
    "    def __init__(self, eval_period, model, data_loader):\n",
    "        self._model = model\n",
    "        self._period = eval_period\n",
    "        self._data_loader = data_loader\n",
    "\n",
    "    def _do_loss_eval(self):\n",
    "        # Copying inference_on_dataset from evaluator.py\n",
    "        total = len(self._data_loader)\n",
    "        num_warmup = min(5, total - 1)\n",
    "\n",
    "        start_time = time.perf_counter()\n",
    "        total_compute_time = 0\n",
    "        losses = []\n",
    "        for idx, inputs in enumerate(self._data_loader):\n",
    "            if idx == num_warmup:\n",
    "                start_time = time.perf_counter()\n",
    "                total_compute_time = 0\n",
    "            start_compute_time = time.perf_counter()\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.synchronize()\n",
    "            total_compute_time += time.perf_counter() - start_compute_time\n",
    "            iters_after_start = idx + 1 - num_warmup * int(idx >= num_warmup)\n",
    "            seconds_per_img = total_compute_time / iters_after_start\n",
    "            if idx >= num_warmup * 2 or seconds_per_img > 5:\n",
    "                total_seconds_per_img = (time.perf_counter() - start_time) / iters_after_start\n",
    "                eta = datetime.timedelta(seconds=int(total_seconds_per_img * (total - idx - 1)))\n",
    "                log_every_n_seconds(\n",
    "                    logging.INFO,\n",
    "                    \"Loss on Validation  done {}/{}. {:.4f} s / img. ETA={}\".format(\n",
    "                        idx + 1, total, seconds_per_img, str(eta)\n",
    "                    ),\n",
    "                    n=5,\n",
    "                )\n",
    "            loss_batch = self._get_loss(inputs)\n",
    "            losses.append(loss_batch)\n",
    "        mean_loss = np.mean(losses)\n",
    "        self.trainer.storage.put_scalar('validation_loss', mean_loss)\n",
    "        comm.synchronize()\n",
    "\n",
    "        return losses\n",
    "\n",
    "    def _get_loss(self, data):\n",
    "        # How loss is calculated on train_loop\n",
    "        metrics_dict = self._model(data)\n",
    "        metrics_dict = {\n",
    "            k: v.detach().cpu().item() if isinstance(v, torch.Tensor) else float(v)\n",
    "            for k, v in metrics_dict.items()\n",
    "        }\n",
    "        total_losses_reduced = sum(loss for loss in metrics_dict.values())\n",
    "        return total_losses_reduced\n",
    "\n",
    "\n",
    "    def after_step(self):\n",
    "        next_iter = self.trainer.iter + 1\n",
    "        is_final = next_iter == self.trainer.max_iter\n",
    "        if is_final or (self._period > 0 and next_iter % self._period == 0):\n",
    "            self._do_loss_eval()\n",
    "        self.trainer.storage.put_scalars(timetest=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train_samples = 4\n",
    "DatasetCatalog.register(\n",
    "    \"mutaSCAN_train\",\n",
    "    lambda: get_data_dicts(f'datasets/train/coco_{n_train_samples}_samples.json', f'caches/train_samples'))\n",
    "MetadataCatalog.get(\"mutaSCAN_train\").set(thing_classes=[\"0\", \"1\", \"2\"])\n",
    "\n",
    "DatasetCatalog.register(\n",
    "    \"mutaSCAN_valid\",\n",
    "    lambda: get_data_dicts(f'datasets/valid/coco.json', f'caches/valid_samples'))\n",
    "MetadataCatalog.get(\"mutaSCAN_valid\").set(thing_classes=[\"0\", \"1\", \"2\"])\n",
    "\n",
    "dataset_dicts = get_data_dicts(f'datasets/train/coco_{n_train_samples}_samples.json', 'caches')\n",
    "mutaSCAN_metadata = MetadataCatalog.get(\"mutaSCAN_train\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train dataset\n",
    "dataset_dicts = DatasetCatalog.get('mutaSCAN_train')\n",
    "d = random.sample(dataset_dicts, 1)[0]\n",
    "im = cv2.imread(d[\"file_name\"])\n",
    "visualizer = Visualizer(im, metadata=mutaSCAN_metadata, scale=1.0)\n",
    "vis = visualizer.draw_dataset_dict(d)\n",
    "cv2_imshow(vis.get_image(), bgr2rgb=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid dataset\n",
    "dataset_dicts = DatasetCatalog.get('mutaSCAN_valid')\n",
    "d = random.sample(dataset_dicts, 1)[0]\n",
    "im = cv2.imread(d[\"file_name\"])\n",
    "visualizer = Visualizer(im, metadata=mutaSCAN_metadata, scale=1.0)\n",
    "vis = visualizer.draw_dataset_dict(d)\n",
    "cv2_imshow(vis.get_image(), bgr2rgb=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuration for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "\n",
    "# get configuration from model_zoo\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\"))\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\")\n",
    "\n",
    "cfg.DATALOADER.NUM_WORKERS = 48\n",
    "\n",
    "# Model\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(mutaSCAN_metadata.thing_classes)\n",
    "\n",
    "# Solver\n",
    "cfg.SOLVER.BASE_LR = 0.0003\n",
    "cfg.SOLVER.MAX_ITER = 6000\n",
    "cfg.SOLVER.STEPS = (2000, 4000)\n",
    "cfg.SOLVER.GAMMA = 0.3\n",
    "cfg.SOLVER.WARMUP_FACTOR = 0.001\n",
    "cfg.SOLVER.WARMUP_ITERS = 200\n",
    "cfg.SOLVER.IMS_PER_BATCH = 8\n",
    "cfg.SOLVER.CHECKPOINT_PERIOD = 100\n",
    "\n",
    "# Test\n",
    "cfg.TEST.DETECTIONS_PER_IMAGE = 100\n",
    "cfg.TEST.EVAL_PERIOD = 100\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.75\n",
    "\n",
    "# DATASETS\n",
    "cfg.DATASETS.TRAIN = ('mutaSCAN_train',)\n",
    "cfg.DATASETS.TEST = ('mutaSCAN_valid',)\n",
    "\n",
    "# Output Model\n",
    "cfg.OUTPUT_DIR = str(utility.generate_timedate_cache_file(OUTPUT_DIR, suffix=f'{n_train_samples}_samples'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MetadataCatalog.get(cfg.DATASETS.TRAIN[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from detectron2.data.catalog import Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Metadata(name='', thing_classes=['0', '1', '2'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_list = [\n",
    "    T.RandomBrightness(0.35, 1.6),\n",
    "    T.RandomContrast(0.25, 1.6),\n",
    "    T.RandomSaturation(0.25, 1.4),\n",
    "    T.RandomRotation(angle=[0, 180]),\n",
    "    T.RandomLighting(0.7),\n",
    "    T.RandomFlip(prob=0.5, horizontal=False, vertical=True),\n",
    "]\n",
    "\n",
    "class CustomTrainer(DefaultTrainer):\n",
    "    @classmethod\n",
    "    def build_train_loader(cls, cfg):\n",
    "        return build_detection_train_loader(cfg, mapper=CustomMapper(cfg, transform_list))\n",
    "\n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "        if output_folder is None:\n",
    "            output_folder = os.path.join(cfg.OUTPUT_DIR, \"inference\")\n",
    "            utility.create_directory(cfg.OUTPUT_DIR)\n",
    "        return COCOEvaluator(dataset_name, cfg, True, output_folder)\n",
    "\n",
    "    def build_hooks(self):\n",
    "        hooks = super().build_hooks()\n",
    "        hooks.insert(-1,LossEvalHook(\n",
    "            cfg.TEST.EVAL_PERIOD,\n",
    "            self.model,\n",
    "            build_detection_test_loader(\n",
    "                self.cfg,\n",
    "                self.cfg.DATASETS.TEST[0],\n",
    "                CustomMapper(cfg, [])\n",
    "            )\n",
    "        ))\n",
    "        return hooks\n",
    "\n",
    "mapper = CustomMapper(cfg, transform_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_name = 'CustomTrainer_config.yaml'\n",
    "trainer = CustomTrainer(cfg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start to Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utility.create_directory(cfg.OUTPUT_DIR)\n",
    "with open(Path(cfg.OUTPUT_DIR) / Path(config_name), 'w') as f:\n",
    "    f.write(cfg.dump())\n",
    "trainer.resume_or_load(resume=True)\n",
    "trainer.train()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use model for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.MODEL.WEIGHTS = str(OUTPUT_DIR / Path('20230316_195019_153387_5_samples') / Path('model_final.pth'))\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.85\n",
    "predictor = DefaultPredictor(cfg, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = cv2.imread(glob('caches/test_samples/*_sample2_9*.png')[0])\n",
    "\n",
    "outputs = predictor(im)\n",
    "print(outputs[\"instances\"].pred_classes)\n",
    "\n",
    "v = Visualizer(im, MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1, instance_mode=ColorMode.IMAGE)\n",
    "out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "cv2_imshow(out.get_image(), bgr2rgb=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minute = 10\n",
    "for i in range(6):\n",
    "    im = cv2.imread(glob(f'caches/test_samples/*_sample{i + 1}_{minute - 1}*.png')[0])\n",
    "    outputs = predictor(im)\n",
    "    print(outputs[\"instances\"].pred_classes)\n",
    "    v = Visualizer(im, MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1, instance_mode=ColorMode.IMAGE)\n",
    "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    cv2_imshow(out.get_image(), bgr2rgb=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minute = 30\n",
    "for i in range(6):\n",
    "    im = cv2.imread(glob(f'caches/test_samples/*_sample{i + 1}_{minute - 1}*.png')[0])\n",
    "    outputs = predictor(im)\n",
    "    print(outputs[\"instances\"].pred_classes)\n",
    "    v = Visualizer(im, MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1, instance_mode=ColorMode.IMAGE)\n",
    "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    cv2_imshow(out.get_image(), bgr2rgb=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_folder = './output/model_iter4000_lr0005_wf1_date2020_03_20__05_16_45'\n",
    "\n",
    "def load_json_arr(json_path):\n",
    "    lines = []\n",
    "    with open(json_path, 'r') as f:\n",
    "        for line in f:\n",
    "            lines.append(json.loads(line))\n",
    "    return lines\n",
    "\n",
    "experiment_metrics = load_json_arr(experiment_folder + '/metrics.json')\n",
    "\n",
    "plt.plot(\n",
    "    [x['iteration'] for x in experiment_metrics],\n",
    "    [x['total_loss'] for x in experiment_metrics])\n",
    "plt.plot(\n",
    "    [x['iteration'] for x in experiment_metrics if 'validation_loss' in x],\n",
    "    [x['validation_loss'] for x in experiment_metrics if 'validation_loss' in x])\n",
    "plt.legend(['total_loss', 'validation_loss'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mutaSCAN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "58dd376416a726c3a738351c156641797282f248d0409aed44c21e67d1c45b1a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
